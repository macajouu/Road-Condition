{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization \n",
    "\n",
    "### Imports \n",
    "\n",
    "#Fold\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "os.environ[\"image_dim_ordering\"] = \"tf\"\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN, device=cuda2, floatX=float32, exception_verbosity=high\" \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input, Concatenate, Add, Lambda, GlobalAveragePooling2D, Maximum\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from os import scandir, walk\n",
    "except ImportError:\n",
    "    from scandir import scandir, walk\n",
    "\n",
    "### Variable initializations\n",
    "\n",
    "#Fold\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 3\n",
    "nb_epoch = 60\n",
    "\n",
    "mean = 0.38233018\n",
    "std = 0.2534719\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 245, 640\n",
    "\n",
    "\n",
    "# 1. Data manipulation\n",
    "\n",
    "### Load data\n",
    "\n",
    "#Fold\n",
    "\n",
    "#    ---------MINISET---------\n",
    "\n",
    "# train_src_directory = r'/notebooks/datasets/road_condition/miniset/train'\n",
    "# test_src_directory = r'/notebooks/datasets/road_condition/miniset/test'\n",
    "# X_train = np.memmap(os.path.join(train_src_directory, 'X_train_images.h5'), dtype='float32', mode='r', shape=(21701, 245, 640))\n",
    "# Y_train = np.memmap(os.path.join(train_src_directory, 'Y_train_labels.h5'), dtype='float32', mode='r', shape=(21701, 1))\n",
    "# X_validation = np.memmap(os.path.join(test_src_directory, 'X_test_images.h5'), dtype='float32', mode='r', shape=(7042, 245, 640))\n",
    "# Y_validation = np.memmap(os.path.join(test_src_directory, 'Y_test_labels.h5'), dtype='float32', mode='r', shape=(7042, 1))\n",
    "\n",
    "\n",
    "\n",
    "#    ---------DATASET---------\n",
    "\n",
    "network_type = 'all'\n",
    "\n",
    "train_src_directory = r'/notebooks/datasets/road_condition/dataset/train'\n",
    "test_src_directory = r'/notebooks/datasets/road_condition/dataset/test'\n",
    "validation_src_directory = r'/notebooks/datasets/road_condition/dataset/validation'\n",
    "browse_src_directory = r'/notebooks/datasets/road_condition/browse'\n",
    "\n",
    "# test_src_directory = r'/notebooks/datasets/road_condition/dataset/test_unshuffled'\n",
    "# validation_src_directory = r'/notebooks/datasets/road_condition/dataset/validation_unshuffled'\n",
    "\n",
    "# X_test = np.memmap(os.path.join(test_src_directory, 'X_test_images_normalized_easy.h5'), dtype='float32', mode='r', shape=(15067, 245, 640))\n",
    "\n",
    "#Normalized\n",
    "# X_test = np.memmap(os.path.join(test_src_directory, 'X_test_images_normalized.h5'), dtype='float32', mode='r', shape=(16103, 245, 640))\n",
    "X_test = np.memmap(os.path.join(test_src_directory, 'X_test_images.h5'), dtype='float32', mode='r', shape=(16103, 245, 640))\n",
    "Y_test = np.memmap(os.path.join(test_src_directory, network_type, 'Y_test_labels.h5'), dtype='float32', mode='r', shape=(16103, 1))\n",
    "\n",
    "#Normalized\n",
    "# X_validation = np.memmap(os.path.join(validation_src_directory, 'X_validation_images_normalized.h5'), dtype='float32', mode='r', shape=(17200, 245, 640))\n",
    "X_validation = np.memmap(os.path.join(validation_src_directory, 'X_validation_images.h5'), dtype='float32', mode='r', shape=(17200, 245, 640))\n",
    "Y_validation = np.memmap(os.path.join(validation_src_directory, network_type, 'Y_validation_labels.h5'), dtype='float32', mode='r', shape=(17200, 1))\n",
    "\n",
    "X_train = np.memmap(os.path.join(train_src_directory, 'X_train_images.h5'), dtype='float32', mode='r', shape=(74331, 245, 640))\n",
    "Y_train = np.memmap(os.path.join(train_src_directory, network_type, 'Y_train_labels.h5'), dtype='float32', mode='r', shape=(74331, 1))\n",
    "\n",
    "\n",
    "\n",
    "### Preprocess - Ordering, reshaping\n",
    "\n",
    "#Fold\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    X_validation = X_validation.reshape(X_validation.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    X_validation = X_validation.reshape(X_validation.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "\n",
    "\n",
    "# print(Y_train[:10])\n",
    "print(Y_validation.shape)\n",
    "\n",
    "\n",
    "### Info about datasets\n",
    "\n",
    "def print_info(data_set):  \n",
    "    print('Min: ' + str(np.min(data_set)))\n",
    "    print('Max: ' + str(np.max(data_set)))\n",
    "    print('Mean: ' + str(np.mean(data_set)))\n",
    "    print('Stdev: ' + str(np.std(data_set)))\n",
    "\n",
    "print_info(Y_validation)\n",
    "\n",
    "### Balance datasets for the 2-class networks\n",
    "\n",
    "# X_test = np.delete(X_test, 1, 0)\n",
    "# Y_train = np.delete(Y_train, 3, 0)\n",
    "\n",
    "recently_removed = True\n",
    "\n",
    "nr0 = 0\n",
    "nrDel = 0\n",
    "\n",
    "# for i in range(100):\n",
    "#     if Y_test[i][0] == 0:\n",
    "#         if recently_removed is True:\n",
    "#             recently_removed = False\n",
    "#         else:\n",
    "#             X_test = np.delete(X_test, i, 0)\n",
    "#             Y_test = np.delete(Y_test, i, 0)\n",
    "#             recently_removed = True\n",
    "#             nrDel += 1\n",
    "#         nr0 += 1\n",
    "       \n",
    "position = 0    \n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i][0] == 0:\n",
    "        if recently_removed is True:\n",
    "            recently_removed = False\n",
    "            X_train_balanced[position] = X_train[i]\n",
    "            Y_train_balanced[position] = Y_train[i]\n",
    "            position += 1\n",
    "        else:\n",
    "            recently_removed = True\n",
    "            nrDel += 1\n",
    "        nr0 += 1\n",
    "    else:\n",
    "        X_train_balanced[position] = X_train[i]\n",
    "        Y_train_balanced[position] = Y_train[i]\n",
    "        position += 1\n",
    "\n",
    "print('Nr0: ' + str(nr0))\n",
    "print('NrDel: ' + str(nrDel))\n",
    "\n",
    "print('Balanced test')\n",
    "\n",
    "\n",
    "### Modify labels\n",
    "\n",
    "#Fold\n",
    "\n",
    "nr1 = 0\n",
    "nr2 = 0\n",
    "nr3 = 0\n",
    "nr4 = 0\n",
    "nr5 = 0\n",
    "nr6 = 0\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i][0] == 0:\n",
    "        Y_test[i][0] = 1\n",
    "        nr1 += 1\n",
    "    else:\n",
    "        Y_test[i][0] = 0\n",
    "        nr2 += 1\n",
    "        \n",
    "for i in range(len(Y_validation)):\n",
    "    if Y_validation[i][0] == 0:\n",
    "        Y_validation[i][0] = 1\n",
    "        nr3 += 1\n",
    "    else:\n",
    "        Y_validation[i][0] = 0\n",
    "        nr4 += 1\n",
    "        \n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i][0] == 0:\n",
    "        Y_train[i][0] = 1\n",
    "        nr5 += 1\n",
    "    else:\n",
    "        Y_train[i][0] = 0\n",
    "        nr6 += 1\n",
    "\n",
    "print(nr1)\n",
    "print(nr2)\n",
    "print(nr3)\n",
    "print(nr4)\n",
    "print(nr5)\n",
    "print(nr6)\n",
    "\n",
    "### To categorical\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "Y_validation = np_utils.to_categorical(Y_validation, nb_classes)\n",
    "\n",
    "# 2. CNN Architecture\n",
    "\n",
    "### First model\n",
    "\n",
    "#Fold\n",
    "\n",
    "print('Start assembling model')\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(12, (7, 7), strides=(3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "print('1st OUTPUT SHAPE: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Conv2D(24, (5,5), strides=(2, 2), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "print('2nd OUTPUT SHAPE: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "print('3rd OUTPUT SHAPE: ' + str(model.output_shape))\n",
    " \n",
    "model.add(Flatten())\n",
    "\n",
    "print('Flatten: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "\n",
    "print('Fully connected: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "print('Assembled model')\n",
    "\n",
    "### Sequential model\n",
    "\n",
    "#Fold\n",
    "\n",
    "print('Start assembling model')\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(12, (7, 7), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "print('1st OUTPUT SHAPE: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Conv2D(24, (5,5), strides=(2, 2), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(24, (5,5), strides=(1, 1), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "print('2nd OUTPUT SHAPE: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "print('3rd OUTPUT SHAPE: ' + str(model.output_shape))\n",
    " \n",
    "model.add(Flatten())\n",
    "\n",
    "print('Flatten: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "\n",
    "print('Fully connected: ' + str(model.output_shape))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "print('Assembled model')\n",
    "\n",
    "### My graph model\n",
    "\n",
    "#Fold\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "concat_axis = bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "\n",
    "\n",
    "x = Conv2D(24, (7, 7), strides=(2, 3))(inputs)\n",
    "x = BatchNormalization(axis=bn_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "residual = Conv2D(24, (5,5), strides=(1, 1), padding='same', kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "residual = Activation('relu')(residual)\n",
    "\n",
    "residual = Conv2D(24, (5, 5), strides=(1, 1), padding='same', kernel_regularizer = regularizers.l2(0.01))(residual)\n",
    "residual = BatchNormalization(axis=bn_axis)(residual)\n",
    "x = Add()([x, residual])\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(48, (1, 1), padding='same')(x)\n",
    "residual = Conv2D(48, (3, 3), padding='same', kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "residual = Activation('relu')(residual)\n",
    "\n",
    "residual = Conv2D(48, (3, 3), padding='same', kernel_regularizer = regularizers.l2(0.01))(residual)\n",
    "residual = BatchNormalization(axis=bn_axis)(residual)\n",
    "x = Add()([x, residual])\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "scores = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs=scores)\n",
    "\n",
    "\n",
    "### Inception-Resnet util functions\n",
    "\n",
    "def conv2d_bn(x, no_filters, kernel_size, strides=1, padding='same', activation='relu'):\n",
    "    \n",
    "    x = Conv2D(no_filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "    bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    \n",
    "    if block_type == 'A':\n",
    "        branch_0 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3)\n",
    "        branch_2 = conv2d_bn(x, 32, 1)\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3)\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3)\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "        \n",
    "    elif block_type == 'B':\n",
    "        branch_0 = conv2d_bn(x, 64, 1)\n",
    "        branch_1 = conv2d_bn(x, 64, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 64, [7, 1])\n",
    "        branch_1 = conv2d_bn(branch_1, 64, [1, 7])\n",
    "        branches = [branch_0, branch_1]\n",
    "    \n",
    "    elif block_type == 'C':\n",
    "        branch_0 = conv2d_bn(x, 96, 1)\n",
    "        branch_1 = conv2d_bn(x, 96, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 96, [3, 1])\n",
    "        branch_1 = conv2d_bn(branch_1, 96, [1, 3])\n",
    "        branches = [branch_0, branch_1]\n",
    "        \n",
    "    block_name = 'Inception-ResNet-' + block_type + '_' + str(block_idx)\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    \n",
    "    mixed = Concatenate(axis=concat_axis, name=block_name + '_mixed')(branches)\n",
    "    resized = Conv2D(K.int_shape(x)[concat_axis], 1, name=block_name + '_resize')(mixed)\n",
    "    \n",
    "    x = Lambda(lambda inputs, scale : inputs[0] + scale * inputs[1],\n",
    "              output_shape=K.int_shape(x)[1:],\n",
    "              arguments={'scale': scale},\n",
    "              name=block_name)([x, resized])\n",
    "    \n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=block_name + '_ac')(x)\n",
    "        \n",
    "    return x    \n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "### Inception-Resnet-like model \n",
    "\n",
    "def inception_resnet_model_1():\n",
    "\n",
    "    concat_axis = bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "\n",
    "    x = conv2d_bn(model_input, 24, 7, strides=(2, 3), padding='valid')\n",
    "    x = conv2d_bn(x, 48, 5)\n",
    "    x = conv2d_bn(x, 64, 3, strides=(2, 3), padding='valid')\n",
    "\n",
    "\n",
    "    for block_idx in range(1, 2):\n",
    "        x = inception_resnet_block(x, scale=1, block_type='A', block_idx=block_idx)\n",
    "\n",
    "    branch_0 = MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branch_1 = conv2d_bn(x, 48, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 48, 1)\n",
    "    branch_2 = conv2d_bn(x, 48, 3)\n",
    "    branch_2 = conv2d_bn(x, 48, 3, strides=2, padding='valid')\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    x = Concatenate(axis=concat_axis, name='Reduction-A')(branches)\n",
    "\n",
    "    # for block_idx in range(1, 2):\n",
    "    #     x = inception_resnet_block(x, scale=1, block_type='B', block_idx=block_idx)\n",
    "\n",
    "    x = inception_resnet_block(x, scale=1, block_type='B', block_idx=1)\n",
    "#     x = inception_resnet_block(x, scale=0.2, block_type='B', block_idx=2)\n",
    "\n",
    "    branch_0 = MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branch_1 = conv2d_bn(x, 72, 1)\n",
    "    branch_1 = conv2d_bn(x, 72, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 72, 1)\n",
    "    branch_2 = conv2d_bn(x, 96, 3, strides=2, padding='valid')\n",
    "    branch_3 = conv2d_bn(x, 72, 1)\n",
    "    branch_3 = conv2d_bn(x, 72, 3, strides=2, padding='valid')\n",
    "    branches = [branch_0, branch_1, branch_2, branch_3]\n",
    "    x = Concatenate(axis=concat_axis, name='Reduction-B')(branches)\n",
    "\n",
    "    for block_idx in range(1, 2):\n",
    "        x = inception_resnet_block(x, scale=0.2, block_type='C', block_idx=block_idx)\n",
    "\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "    scores = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs = model_input, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def inception_resnet_model_2():\n",
    "\n",
    "    concat_axis = bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "\n",
    "    x = conv2d_bn(model_input, 24, 7, strides=(2, 3), padding='valid')\n",
    "    x = conv2d_bn(x, 48, 5)\n",
    "    x = conv2d_bn(x, 64, 3, strides=(2, 3), padding='valid')\n",
    "\n",
    "\n",
    "    for block_idx in range(1, 2):\n",
    "        x = inception_resnet_block(x, scale=1, block_type='A', block_idx=block_idx)\n",
    "\n",
    "    branch_0 = MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branch_1 = conv2d_bn(x, 48, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 48, 1)\n",
    "    branch_2 = conv2d_bn(x, 48, 3)\n",
    "    branch_2 = conv2d_bn(x, 48, 3, strides=2, padding='valid')\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    x = Concatenate(axis=concat_axis, name='Reduction-A')(branches)\n",
    "\n",
    "    # for block_idx in range(1, 2):\n",
    "    #     x = inception_resnet_block(x, scale=1, block_type='B', block_idx=block_idx)\n",
    "\n",
    "    x = inception_resnet_block(x, scale=1, block_type='B', block_idx=1)\n",
    "    x = inception_resnet_block(x, scale=0.2, block_type='B', block_idx=2)\n",
    "\n",
    "    branch_0 = MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branch_1 = conv2d_bn(x, 72, 1)\n",
    "    branch_1 = conv2d_bn(x, 72, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 72, 1)\n",
    "    branch_2 = conv2d_bn(x, 96, 3, strides=2, padding='valid')\n",
    "    branch_3 = conv2d_bn(x, 72, 1)\n",
    "    branch_3 = conv2d_bn(x, 72, 3, strides=2, padding='valid')\n",
    "    branches = [branch_0, branch_1, branch_2, branch_3]\n",
    "    x = Concatenate(axis=concat_axis, name='Reduction-B')(branches)\n",
    "\n",
    "    for block_idx in range(1, 2):\n",
    "        x = inception_resnet_block(x, scale=0.2, block_type='C', block_idx=block_idx)\n",
    "\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "    scores = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs = model_input, outputs=scores)\n",
    "    return model\n",
    "\n",
    "### Composed model\n",
    "\n",
    "# model_dry = inception_resnet_model_1()\n",
    "# model_wet = inception_resnet_model_2()\n",
    "# model_snow = inception_resnet_model_1()\n",
    "\n",
    "model = inception_resnet_model_2()\n",
    "\n",
    "### Composed model util functions\n",
    "\n",
    "def composed_predict(image):\n",
    "    \n",
    "    image = image.reshape(1, image.shape[0], image.shape[1], 1)\n",
    "    \n",
    "    #Dry  \n",
    "    scores_dry = model_dry.predict(image)\n",
    "    score_dry = scores_dry[0][1]\n",
    "    #Wet\n",
    "    scores_wet = model_wet.predict(image)\n",
    "    score_wet = scores_wet[0][1]\n",
    "    #Snow\n",
    "    scores_snow = model_snow.predict(image)\n",
    "    score_snow = scores_snow[0][1]\n",
    "    \n",
    "    scores = np.array([score_dry, score_wet, score_snow])\n",
    "    \n",
    "    return scores, scores.argmax()\n",
    "\n",
    "def composed_evaluate(X_images, Y_labels, verbose=1):\n",
    "    \n",
    "    nr_correct = 0\n",
    "    \n",
    "    for i in range(len(X_images)):\n",
    "        \n",
    "        scores, index = composed_predict(X_images[i])\n",
    "        \n",
    "        label_categ = Y_labels[i]\n",
    "        label = label_categ.argmax()\n",
    "        \n",
    "        if index == label:\n",
    "            nr_correct += 1\n",
    "            \n",
    "        if verbose==1 and i % 1000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    accuracy = nr_correct / len(Y_labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "### Model summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### Load and manipulate weights\n",
    "\n",
    "# 17\n",
    "# model.load_weights('models/more_weights_inception_resnet/weights_1_2x1_of3/weights.17-0.87.hdf5')\n",
    "\n",
    "# model.load_weights('models/more_weights_inception_resnet/weights_2_2x1_of4/weights.23-1.01.hdf5')\n",
    "\n",
    "model.load_weights('models/more_weights_1/weights.25-0.30.hdf5')\n",
    "\n",
    "# model.load_weights('models/weights_30_epoch.hdf5')\n",
    "\n",
    "\n",
    "# model_dry.load_weights('models/dry/weights_2/weights.03-0.41.hdf5')\n",
    "# model_wet.load_weights('models/wet/weights_5_2x1_of4/weights.31-0.64.hdf5')\n",
    "# model_snow.load_weights('models/snow/weights_2/weights.13-0.69.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "# weights = model.get_weights()\n",
    "\n",
    "# 3. Training\n",
    "\n",
    "### Compile the model\n",
    "\n",
    "#Fold\n",
    "\n",
    "print('Start compiling model')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Compiled model')\n",
    "\n",
    "### Callback to save weights\n",
    "\n",
    "callbacks = []\n",
    "# callbacks.append(ModelCheckpoint('models/weights_wet.hdf5', save_best_only=True))\n",
    "callbacks.append(ModelCheckpoint('models/more_weights_inception_resnet/weights_2_2x1_of4/weights.{epoch:02d}-{val_loss:.2f}.hdf5', save_best_only=False))\n",
    "\n",
    "### Train the model\n",
    "\n",
    "print('Start fitting model')\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test), callbacks=callbacks, shuffle=True)\n",
    "\n",
    "print('Model fit')\n",
    "\n",
    "# 4. Evaluation\n",
    "\n",
    "### Evaluate single model\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "# score = model.evaluate(X_validation, Y_validation, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "### Evaluate composed model\n",
    "\n",
    "#Fold\n",
    "        \n",
    "# ----- EVALUATE VALIDATION -----    \n",
    "accuracy = composed_evaluate(X_validation, Y_validation)\n",
    "print('Validation accuracy: ' + str(round(accuracy * 100, 2)) + '%')\n",
    "\n",
    "    \n",
    "# ----- EVALUATE TEST -----\n",
    "# accuracy = composed_evaluate(X_test, Y_test)\n",
    "# print('Test accuracy: ' + str(round(accuracy * 100, 2)) + '%')\n",
    "\n",
    "### Evaluate each sequence\n",
    "\n",
    "#### Split images into an array of sequences\n",
    "\n",
    "#Fold\n",
    "\n",
    "nr_seq = 0\n",
    "\n",
    "X_test_sequences = [[]]\n",
    "Y_test_sequences = [[]]\n",
    "\n",
    "#TEST\n",
    "#           2     3     4     5     6     7     8     9     10    11    12    13     14     15     16    17     18     19   \n",
    "changes = [2222, 2334, 2446, 2558, 3684, 4877, 4989, 6103, 6215, 8445, 8743, 8967, 10961, 13161, 13535, 13907, 14719, 16103]\n",
    "\n",
    "# VALIDATION\n",
    "# #           2     3     4     5     6     7     8     9     10    11    12    13     14     15     16    17     18     19 \n",
    "# changes = [2227, 2339, 2451, 2836, 3035, 3675, 5257, 5822, 5934, 6046, 6158, 9820, 11896, 13315, 16334, 16680, 16828, 17200]\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    \n",
    "    if i == changes[row]:\n",
    "        #convert the finished sequance to a numpy array\n",
    "        X_test_sequences[row] = np.array(X_test_sequences[row])\n",
    "        Y_test_sequences[row] = np.array(Y_test_sequences[row])\n",
    "        col = 0\n",
    "        row += 1\n",
    "        X_test_sequences.append([])\n",
    "        Y_test_sequences.append([])\n",
    "        \n",
    "    X_test_sequences[row].append(X_test[i])\n",
    "    Y_test_sequences[row].append(Y_test[i])\n",
    "\n",
    "# also for the last sequence\n",
    "X_test_sequences[row] = np.array(X_test_sequences[row])\n",
    "Y_test_sequences[row] = np.array(Y_test_sequences[row])\n",
    "        \n",
    "# print(Y_test_sequences[2])\n",
    "\n",
    "#### View results per sequence\n",
    "\n",
    "#Fold\n",
    "\n",
    "results = [[]]\n",
    "for i in range(len(X_test_sequences)):\n",
    "\n",
    "    #COMPOSED\n",
    "    score = composed_evaluate(X_test_sequences[i], Y_test_sequences[i], verbose=0)\n",
    "    print('Sequence ' + str(i + 1) + ' ---- accuracy: ' + str(round(score * 100, 2)) + '%')\n",
    "    \n",
    "    #SINGLE\n",
    "#     score = model.evaluate(X_test_sequences[i], Y_test_sequences[i], verbose=0)\n",
    "#     print('Sequence ' + str(i + 1) + ' ---- loss: ' + str(round(score[0], 2)) + ' ---- accuracy: ' + str(round(score[1] * 100, 2)) + '%')\n",
    "    \n",
    "\n",
    "\n",
    "# 5. Prediction\n",
    "\n",
    "### Prediction time\n",
    "\n",
    "#Fold\n",
    "\n",
    "X_predict = X_test[2000 : 2001]\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# score = model.predict(X_predict, batch_size=32)\n",
    "\n",
    "i = 1500\n",
    "scores_dry = model_dry.predict(X_validation[i].reshape(1, X_validation[i].shape[0], X_validation[i].shape[1], 1))\n",
    "score_dry = scores_dry[0][1]\n",
    "#Wet\n",
    "scores_wet = model_wet.predict(X_validation[i].reshape(1, X_validation[i].shape[0], X_validation[i].shape[1], 1))\n",
    "score_wet = scores_wet[0][1]\n",
    "#Snow\n",
    "scores_snow = model_snow.predict(X_validation[i].reshape(1, X_validation[i].shape[0], X_validation[i].shape[1], 1))\n",
    "score_snow = scores_snow[0][1]\n",
    "\n",
    "score = np.array([score_dry, score_wet, score_snow]).argmax()\n",
    "\n",
    "label_categ = Y_validation[i]\n",
    "label = label_categ.argmax()\n",
    "\n",
    "if score == label:\n",
    "    pass\n",
    "\n",
    "# You must convert to milliseconds:\n",
    "dt = int((time.time() - start) * 1000)\n",
    "\n",
    "print('Time taken: ' + str(dt) + ' millis')\n",
    "\n",
    "\n",
    "### Predict result for an image in the dataset\n",
    "\n",
    "## Fold\n",
    "\n",
    "index = 12400\n",
    "\n",
    "if True:\n",
    "\n",
    "#     img_sample = X_validation[index]\n",
    "    img_sample = X_test[index]\n",
    "#     img_sample = X_train[index]\n",
    "    \n",
    "\n",
    "    sh = img_sample.shape\n",
    "    img = img_sample.reshape(sh[0], sh[1])\n",
    "\n",
    "    plt.figure(figsize=(24,10))\n",
    "    plt.imshow(img, cmap='gray', aspect='auto');\n",
    "    # plt.colorbar()\n",
    "\n",
    "\n",
    "#     score, max_index = composed_predict(img_sample.reshape(sh[0], sh[1]))\n",
    "#     score *= 100\n",
    "\n",
    "    \n",
    "    score = model.predict(img_sample.reshape(1, sh[0], sh[1], sh[2]))\n",
    "    score = score[0] * 100\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    score = [round(x,2) for x in score]\n",
    "          \n",
    "    categs = ['Dry', 'Wet', 'Snow']\n",
    "\n",
    "    label_categ = Y_test[index]\n",
    "#     label_categ = Y_train[index]\n",
    "#     label_categ = Y_validation[index]\n",
    "    \n",
    "    label = label_categ.argmax()\n",
    "    \n",
    "    print('Expected: ' + categs[label] + '\\n')\n",
    "\n",
    "    for i in range(len(score)):\n",
    "        print(categs[i] + ' - ' + str(score[i]) + ' %')\n",
    "        \n",
    "\n",
    "### Browse an image and predict result\n",
    "\n",
    "for file in scandir(browse_src_directory):\n",
    "    \n",
    "    image_sample = cv2.imread(file.path, 0)\n",
    "    print(image_sample.shape)\n",
    "    \n",
    "    height, width = image_sample.shape[:2]\n",
    "    \n",
    "    #CROP\n",
    "    image_sample = image_sample[height // 3 : , :]\n",
    "    \n",
    "    #new height after crop\n",
    "    height = image_sample.shape[0]\n",
    "\n",
    "    #DOWNSAMPLE\n",
    "    image_sample = cv2.resize(image_sample, (img_cols, img_rows), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    image_sample = (image_sample.astype(float) - mean) / std\n",
    "#     image_sample = image_sample.astype(float) / 128\n",
    "\n",
    "#     print(image_sample.shape)\n",
    "    print(np.min(image_sample))\n",
    "\n",
    "    sh = image_sample.shape\n",
    "    \n",
    "    score, index = composed_predict(image_sample)\n",
    "#     score = model.predict(image_sample.reshape(1, sh[0], sh[1], 1))\n",
    "    print(score)\n",
    "    print(index)\n",
    "    \n",
    "    plt.figure(figsize=(24,12))\n",
    "    plt.imshow(image_sample, cmap='gray', aspect='auto');\n",
    "\n",
    "# 6. Visualisation\n",
    "\n",
    "### Obtain the outputs of each layer\n",
    "\n",
    "#Fold\n",
    "\n",
    "inp = model.input\n",
    "outputs = [layer.output for layer in model.layers if layer.name.startswith('activation')]\n",
    "\n",
    "feedForward = K.function([inp] + [K.learning_phase()], outputs)\n",
    "\n",
    "# Testing\n",
    "\n",
    "#img_sample = X_validation[2]\n",
    "\n",
    "test = img_sample[np.newaxis, :]\n",
    "layer_outs = feedForward([test, 1.])\n",
    "\n",
    "print(layer_outs[0].shape)\n",
    "\n",
    "# layer_outs = layer_outs[: len(layer_outs) - 4]\n",
    "\n",
    "#reshape the outputs so that they are easier to plot\n",
    "for layer, i in zip(layer_outs, range(len(layer_outs))):\n",
    "    layer_outs[i] = np.swapaxes(layer_outs[i], 1, 3)\n",
    "    layer_outs[i] = np.swapaxes(layer_outs[i], 2, 3)\n",
    "    layer_outs[i] = layer_outs[i][0]\n",
    "    print(layer_outs[i].shape)\n",
    "\n",
    "# print(layer_outs[0].shape)\n",
    "\n",
    "\n",
    "### Plot activations on a particular layer\n",
    "\n",
    "#Fold\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "layer = layer_outs[1]\n",
    "\n",
    "# print(layer.shape)\n",
    "\n",
    "extent = (-8, 4, -4, 3)\n",
    "fig = plt.figure(1, (30, 100))\n",
    "\n",
    "\n",
    "grid = ImageGrid(fig, 111,\n",
    "                  nrows_ncols=(12, 2),\n",
    "                  direction=\"row\",\n",
    "                  axes_pad=0.5,\n",
    "                  add_all=True,\n",
    "                  label_mode=\"1\",\n",
    "                  share_all=True,\n",
    "#                   cbar_location=\"top\",\n",
    "#                   cbar_mode=\"single\",\n",
    "#                   cbar_size=\"5%\",\n",
    "                  cbar_location=\"left\",\n",
    "                  cbar_mode=\"each\", \n",
    "                  cbar_size=\"2%\",\n",
    "                  cbar_pad=0.1,\n",
    "                  )\n",
    "\n",
    "# vmax, vmin = np.max(layer), np.min(layer)\n",
    "\n",
    "for i in range (layer.shape[0]):\n",
    "\n",
    "    vmax, vmin = np.max(layer[i]), np.min(layer[i])\n",
    "    norm = matplotlib.colors.Normalize(vmax=vmax, vmin=vmin)\n",
    "\n",
    "    im = grid[i].imshow(layer[i], norm=norm, #extent=extent,\n",
    "                           cmap=\"gray\",\n",
    "#                            origin=\"lower\",\n",
    "                           interpolation=\"nearest\")\n",
    "\n",
    "    grid[i].cax.colorbar(im)\n",
    "    grid[i].cax.toggle_label(True)\n",
    "\n",
    "plt.draw()\n",
    "plt.show()\n",
    "\n",
    "### View Weights\n",
    "\n",
    "#Fold\n",
    "\n",
    "[print(weights[i].shape) for i in range(len(weights))];\n",
    "\n",
    "# w = weights[0].reshape(weights[0].shape[3], weights[0].shape[0], weights[0].shape[1])\n",
    "\n",
    "\n",
    "w = weights[-2]\n",
    "\n",
    "print(w.shape)\n",
    "\n",
    "\n",
    "w = np.swapaxes(w, 0, 2)\n",
    "w = np.swapaxes(w, 1, 3)\n",
    "w = w[0]\n",
    "\n",
    "print(w.shape)\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "\n",
    "# fig = plt.figure(1, (5, 10))\n",
    "fig = plt.figure(1, (20, 40))\n",
    "\n",
    "grid = ImageGrid(fig, 111,\n",
    "                  nrows_ncols=(4, 3),\n",
    "#                   nrows_ncols=(1, 2),\n",
    "                  direction=\"row\",\n",
    "                  axes_pad=0.5,\n",
    "                  add_all=True,\n",
    "                  label_mode=\"1\",\n",
    "                  share_all=True,\n",
    "#                   cbar_location=\"top\",\n",
    "#                   cbar_mode=\"single\",\n",
    "#                   cbar_size=\"5%\",\n",
    "                  cbar_location=\"left\",\n",
    "                  cbar_mode=\"each\", \n",
    "                  cbar_size=\"2%\",\n",
    "                  cbar_pad=0.1,\n",
    "                  )\n",
    "\n",
    "print(w)\n",
    "vmax, vmin = np.max(w), np.min(w)\n",
    "\n",
    "print('Min: ' + str(vmin))\n",
    "print('Max: ' + str(vmax))\n",
    "\n",
    "for i in range (w.shape[0]):\n",
    "\n",
    "    vmax, vmin = np.max(w[i]), np.min(w[i])\n",
    "    norm = matplotlib.colors.Normalize(vmax=vmax, vmin=vmin)\n",
    "\n",
    "    im = grid[i].imshow(w[i], norm=norm, #extent=extent,\n",
    "                           cmap=\"gray\",\n",
    "#                            origin=\"lower\", \n",
    "                           interpolation=\"nearest\"\n",
    "                       )\n",
    "\n",
    "    grid[i].cax.colorbar(im)\n",
    "    grid[i].cax.toggle_label(True)\n",
    "\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
